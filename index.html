<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="End-to-End Navigation with Vision Language Models.">
  <meta name="keywords" content="Navigation, Robotics, Embodied AI, VLM">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>VLMnav: End-to-End Navigation with Vision Language Models</title>


  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/map.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
    </div>
    </div>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">VLMnav: End-to-End Navigation with VLMs</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="mailto:dylangoetting@berkeley.edu">Dylan Goetting</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://hgaurav2k.github.io/">Himanshu Gaurav Singh</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://antonilo.github.io/">Antonio Loquercio</a><sup>2</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of California Berkeley,</span>
            <span class="author-block"><sup>2</sup>University of Pennsylvania</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="link"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="link"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="link"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We present VLMnav, an embodied framework to transform a Vision and Language Model (VLM) into an end-to-end navigation policy. 
            In contrast to prior work, we do not rely on a separation between perception, planning, and control; instead, we use a VLM to directly select actions in one step. 
            Surprisingly, we find that a VLM can be used as an end-to-end policy zero-shot, i.e., without any fine-tuning or exposure to navigation data. 
            This makes our approach open-ended and generalizable to any downstream navigation task.
          </p>
          <p>
            We run an extensive study to evaluate the performance of our approach in comparison to baseline prompting methods. 
            In addition, we perform a design analysis to understand the most impactful design decisions.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img id="teaser" src="./shared/pivot.gif" alt="teaser" height="100%">

      <h2 class="subtitle has-text-centered">
        <span class="dnerf" > 
      </h2>
    </div>
  </div>
</section>

<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Example Trajectories</h2>
      </div>
    </div>
    <div class="container">
      
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <img id="steve" src="./static/images/animation.gif" alt="teaser" height="100%">
          <p class="subtitle has-text-centered">Navigation goal: chair </p>
        </div>
        <div class="item item-chair-tp">
          <img id="chair-tp" src="./static/images/animation.gif" alt="teaser" height="100%">
          <p class="subtitle has-text-centered">Navigation goal: sofa</p>
        </div>
        <div class="item item-coffee">
          <img id="coffee" src="./static/images/animation.gif" alt="teaser" height="100%">
          <p class="subtitle has-text-centered">Navigation goal: bed </p>
        </div>
        <div class="item item-toby">
          <img id="toby" src="./static/images/animation.gif" alt="teaser" height="100%">
          <p class="has-text-centered">Navigation goal: TV</p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
      <h2 class="title is-3">Overview</h2>
      <div class="hero-body">
        <img id="teaser" src="./static/images/overview.png" alt="Overview" height="100%">
        <h2 class="subtitle has-text-centered">
        <span class="dnerf">
          Our method is made up of four key components: (i) Navigability, (ii) Action Proposer, (iii) Projection, and (iv) Prompting. An example update step to the map shows the marking of new area as explored (gray) or unexplored (green)
        </span>
        </h2>
      </div>
      </div>
    </div>
  </div>

  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
          <p>
            We present VLMnav, designed as a navigation system that takes as input goal G, which can be specified in language or an image, RGB-D image, pose and subsequently outputs action a. The action space consists of rotation about the yaw axis and displacement along the frontal axis in the robot frame, which allows all actions to be expressed in polar coordinates. As it is known that VLMs struggle to reason about continuous coordinates, we instead transform the navigation problem into the selection of an action from a discrete set of options. Our core idea is to choose these action options in a way that avoids obstacle collisions and promotes exploration.

          </p>
          <p>
            We start by determining the navigability of the local region by estimating the distance to obstacles using a depth image. Similar to other works, we use the depth image and pose information to maintain a top-down voxel map of the scene, and notably mark voxels as explored or unexplored.
            Such a map is used by an Action Proposer to determine a set of actions that avoid obstacles and promote exploration. We then project this set of possible actions to the first-person-view RGB image with the projection component. Finally, the VLM takes as input this image and a carefully crafted prompt to select an action, which the agent executes. To determine episode termination, we use a separate VLM call.
          </p>
        </div>
      </div>
    </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">What is the model thinking?</h2>
      </div>
    </div>
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <img id="steve" src="./static/images/image.png" alt="teaser" height="100%">
          <p class="subtitle is-size-7 has-text-centered">I see a TV and a TV stand to my left, a window to my right, and a chair in front of me. It looks like I am in a living room. I should go in the direction of the chair. Action 2 will move me closer to the chair. {'action': 2}</p>
        </div>
        <div class="item item-chair-tp">
          <img id="chair-tp" src="./static/images/image.png" alt="teaser" height="100%">
          <p class="subtitle is-size-7 has-text-centered">I see a TV and a TV stand to my left, a window to my right, and a chair in front of me. It looks like I am in a living room. I should go in the direction of the chair. Action 2 will move me closer to the chair. {'action': 2}</p>
        </div>
        <div class="item item-coffee">
          <img id="coffee" src="./static/images/image.png" alt="teaser" height="100%">
          <p class="subtitle is-size-7 has-text-centered">I see a TV and a TV stand to my left, a window to my right, and a chair in front of me. It looks like I am in a living room. I should go in the direction of the chair. Action 2 will move me closer to the chair. {'action': 2}</p>
        </div>
        <div class="item item-toby">
          <img id="toby" src="./static/images/image.png" alt="teaser" height="100%">
          <p class="subtitle is-size-7 has-text-centered">I see a TV and a TV stand to my left, a window to my right, and a chair in front of me. It looks like I am in a living room. I should go in the direction of the chair. Action 2 will move me closer to the chair. {'action': 2}</p>
        </div>
      </div>
    </div>
  </div>
</section>




<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-fill">

      <!-- Visual Effects. -->
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Baseline: PIVOT</h2>
          <div class="columns is-centered">
            <div class="column content">
              <p>
                PIVOT (google 2024), is a similar visual-prompting method that uses the VLM's feedback to iteratively fit an action gaussian at each timestep. In this example, the agent's goal is to reach a bed, which it does successfully after a lot of time spent slowly turning around
              </p>
              <img id="pivot" src="./shared/pivot_bed_success.gif" alt="teaser" height="100%">
              <p>
                In this example, the agent's goal is to reach the toilet, but PIVOT struggles with multi-modality and avoiding obstacles.
              </p>
              <img id="pivot" src="./shared/PIVOT_toilet_fail.gif" alt="teaser" height="100%">
            </div>
        </div>
      </div>
      <!--/ Visual Effects. -->

      <!-- Matting. -->
      <div class="column">
        <h2 class="title is-3">Baseline: Ours -nav & prop</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              To evaluate the direct impact of our prompting method, we run a baseline without the navigability and action_proposer modules. In this example, the agent's goal is to reach a bed, but it gets stuck behind obstacles
            </p>
            <img id="pivot" src="./shared/base_bed_fail.gif" alt="teaser" height="100%">

          </div>
          <div class="column content">
            <p>
              In this example, the agent's goal is to reach the toilet, which it completes successfully but after wasting a lot of time in the corner.
            </p>
            <img id="pivot" src="./shared/base_success_toilet.gif" alt="teaser" height="100%">
          </div>
        </div>
      </div>
    </div>
    <!--/ Matting. -->

    <!-- Animation. -->
    <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Animation</h2> -->

        <!-- Interpolating. -->
        <!-- <h3 class="title is-4">Interpolating states</h3>
        <div class="content has-text-justified">
          <p>
            We can also animate the scene by interpolating the deformation latent codes of two input
            frames. Use the slider here to linearly interpolate between the left frame and the right
            frame.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/image.png"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>Start Frame</p>
          </div>
          <div class="column interpolation-video-column">
            <div id="interpolation-image-wrapper">
              Loading...
            </div>
            <input class="slider is-fullwidth is-large is-info"
                   id="interpolation-slider"
                   step="1" min="0" max="100" value="0" type="range">
          </div>
          <div class="column is-3 has-text-centered">
            <img src="./static/images/image.png"
                 class="interpolation-image"
                 alt="Interpolation end reference image."/>
            <p class="is-bold">End Frame</p>
          </div>
        </div>
        <br/> -->
        <!--/ Interpolating. -->

        <!-- Re-rendering. -->
        <!-- <h3 class="title is-4">Re-rendering the input video</h3>
        <div class="content has-text-justified">
          <p>
            Using <span class="dnerf">Nerfies</span>, you can re-render a video from a novel
            viewpoint such as a stabilized camera by playing back the training deformations.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 width="75%">
            <source src="./static/videos/animation.gif"
                    type="video/mp4">
          </video>
        </div> -->
        <!--/ Re-rendering. -->

      <!-- </div>
    </div> -->
    <!--/ Animation. -->


    <!-- Concurrent Work. -->
    <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            There's a lot of excellent work that was introduced around the same time as ours.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an idea similar to our windowed position encoding for coarse-to-fine optimization.
          </p>
          <p>
            <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
            both use deformation fields to model non-rigid scenes.
          </p>
          <p>
            Some works model videos with a NeRF by directly modulating the density, such as <a href="https://video-nerf.github.io/">Video-NeRF</a>, <a href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a href="https://neural-3d-video.github.io/">DyNeRF</a>
          </p>
          <p>
            There are probably many more by the time you are reading this. Check out <a href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
          </p>
        </div>
      </div>
    </div> -->
    <!--/ Concurrent Work. -->

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{goetting2024vlmnav,
  author    = {Goetting, Dylan and Singh, Himanshu Gaurav and Loquercio, Antonio},
  title     = {VLMnav: End-to-End navigation with Vision Language Models},
  journal   = {arxiv},
  year      = {2024},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="link">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="link" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is adapted from <a rel="Nerfies" href="http://nerfies.github.io/">Nerfies</a>, licenced under a <a rel="Creative Commons Attribution-ShareAlike 4.0 International License" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>